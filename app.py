import streamlit as st
import os
import glob
import json
import tempfile
from datetime import datetime
import hashlib
from langchain_community.llms import LlamaCpp
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler

# --- 1. åŸºæœ¬è¨­å®š & CSS ---
# ãƒšãƒ¼ã‚¸ã®åŸºæœ¬çš„ãªè¨­å®šï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ã‚¤ã‚³ãƒ³ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰ã‚’è¡Œã„ã¾ã™ã€‚
st.set_page_config(
    page_title="PocketAI Mentor",
    page_icon="ğŸ§ ",
    layout="wide"
)

# --- UIæ”¹å–„ã®ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ CSS ---
# Streamlitã®æ¨™æº–ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ä¸Šæ›¸ãã—ã€ã‚ˆã‚Šãƒ¢ãƒ€ãƒ³ãªè¦‹ãŸç›®ã«ã—ã¾ã™ã€‚
st.markdown("""
<style>
    /* ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ */
    .stChatMessage {
        border-radius: 10px;
        padding: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .stButton>button {
        border-radius: 8px;
        border: 1px solid transparent;
        transition: all 0.2s ease-in-out;
    }
    .stButton>button:hover {
        border-color: #4A90E2;
        color: #4A90E2;
    }
    /* ãƒ—ãƒ©ã‚¤ãƒãƒªãƒœã‚¿ãƒ³ï¼ˆèª­ã¿è¾¼ã‚€ãƒœã‚¿ãƒ³ï¼‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .stButton>button[kind="primary"] {
        background-color: #4A90E2;
    }
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ (ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒ) */
    [data-testid="stSidebar"] {
        background-color: #1E1E1E; /* é»’ã«è¿‘ã„ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼ */
    }
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®å…¨è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆè‰²ã‚’æ˜ã‚‹ã„è‰²ã«è¨­å®š */
    [data-testid="stSidebar"] * {
        color: #FAFAFA; /* å¯èª­æ€§ã®é«˜ã„ã‚ªãƒ•ãƒ›ãƒ¯ã‚¤ãƒˆ */
    }
    /* å‚ç…§ã‚½ãƒ¼ã‚¹è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ */
    .source-container {
        border: 1px solid #E0E0E0;
        border-radius: 8px;
        padding: 1rem;
        margin-top: 1rem;
        background-color: #FAFAFA;
    }
</style>
""", unsafe_allow_html=True)


# --- å®šæ•°å®šç¾© ---
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚„ãƒ¢ãƒ‡ãƒ«åã‚’å®šç¾©ã—ã¾ã™ã€‚
MODELS_DIR = "./models/"
UPLOADED_DOCS_DIR = "./uploaded_docs/"
CONVERSATIONS_DIR = "./conversations/"
VECTORSTORE_DIR = "./faiss_index_cache/"
EMBEDDING_MODEL = "intfloat/multilingual-e5-large"

# --- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è‡ªå‹•ä½œæˆ ---
# å¿…è¦ãªãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ã€è‡ªå‹•çš„ã«ä½œæˆã—ã¾ã™ã€‚
for dir_path in [MODELS_DIR, UPLOADED_DOCS_DIR, CONVERSATIONS_DIR, VECTORSTORE_DIR]:
    os.makedirs(dir_path, exist_ok=True)


# --- 2. Streamlitã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ© ---
# LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§UIã«è¡¨ç¤ºï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹ã§ã™ã€‚
class StreamlitCallbackHandler(BaseCallbackHandler):
    """LLMã‹ã‚‰ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§UIã«æç”»ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©"""
    def __init__(self, placeholder):
        self.placeholder = placeholder
        self.text = ""

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚Œã‚‹ãŸã³ã«å‘¼ã³å‡ºã•ã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰"""
        # å‡¦ç†å†…å®¹: ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€£çµã—ã€UIã«è¡¨ç¤ºã—ã¾ã™ã€‚
        self.text += token
        self.placeholder.markdown(self.text + "â–Œ") # ã‚«ãƒ¼ã‚½ãƒ«é¢¨ã®è¨˜å·ã‚’è¿½åŠ 

    def on_llm_end(self, response, **kwargs) -> None:
        """LLMã®å¿œç­”ãŒå®Œäº†ã—ãŸã¨ãã«å‘¼ã³å‡ºã•ã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰"""
        # å‡¦ç†å†…å®¹: æœ€çµ‚çš„ãªãƒ†ã‚­ã‚¹ãƒˆã§ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’æ›´æ–°ã—ã¾ã™ã€‚
        self.placeholder.markdown(self.text)


# --- 3. ã‚³ã‚¢æ©Ÿèƒ½ã®é–¢æ•° ---

@st.cache_resource
def load_embeddings(model_name: str):
    """
    åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€Streamlitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã§å†åˆ©ç”¨ã—ã¾ã™ã€‚
    å‡¦ç†å†…å®¹: æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«åã®HuggingFaceåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    """
    with st.spinner("Embeddingãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™..."):
        return HuggingFaceEmbeddings(model_name=model_name)

def get_vectorstore_path(pdf_files: list) -> str:
    """
    é¸æŠã•ã‚ŒãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã®çµ„ã¿åˆã‚ã›ã‹ã‚‰ã€ä¸€æ„ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    å‡¦ç†å†…å®¹: ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚½ãƒ¼ãƒˆã—ã¦çµåˆã—ã€MD5ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®šã—ã¾ã™ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€åŒã˜PDFã®çµ„ã¿åˆã‚ã›ã®å ´åˆã¯åŒã˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚
    """
    sorted_files = sorted([os.path.basename(f) for f in pdf_files])
    identifier = "".join(sorted_files)
    file_hash = hashlib.md5(identifier.encode()).hexdigest()
    return os.path.join(VECTORSTORE_DIR, f"{file_hash}.faiss")


def create_rag_chain(llm, embeddings, pdf_files: list):
    """
    é¸æŠã•ã‚ŒãŸPDFã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«DBã‚’æ§‹ç¯‰ï¼ˆã¾ãŸã¯èª­è¾¼ï¼‰ã—ã€RAGãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚
    å‡¦ç†å†…å®¹:
    1. é¸æŠã•ã‚ŒãŸPDFã®çµ„ã¿åˆã‚ã›ã«å¯¾ã™ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã™ã‚Œã°ãã‚Œã‚’èª­ã¿è¾¼ã¿ã€ãªã‘ã‚Œã°PDFã‚’èª­ã¿è¾¼ã‚“ã§ãƒ™ã‚¯ãƒˆãƒ«DBã‚’æ–°è¦ä½œæˆãƒ»ä¿å­˜ã—ã¾ã™ã€‚
    3. LLMã¨ãƒ™ã‚¯ãƒˆãƒ«DBã‚’çµ„ã¿åˆã‚ã›ãŸRetrievalQAãƒã‚§ãƒ¼ãƒ³ã‚’è¿”ã—ã¾ã™ã€‚
    """
    vectorstore_path = get_vectorstore_path(pdf_files)

    if not os.path.exists(vectorstore_path):
        with st.spinner("PDFã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
            all_documents = []
            for pdf_file in pdf_files:
                loader = PyMuPDFLoader(pdf_file)
                all_documents.extend(loader.load())

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            texts = text_splitter.split_documents(all_documents)
            db = FAISS.from_documents(texts, embeddings)
            db.save_local(vectorstore_path)
            st.success(f"ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ã€Œ{vectorstore_path}ã€ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        with st.spinner(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            db = FAISS.load_local(
                vectorstore_path, embeddings, allow_dangerous_deserialization=True
            )

    retriever = db.as_retriever(search_kwargs={"k": 4})
    
    template = """
### æŒ‡ç¤º:
ä»¥ä¸‹ã®ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€ã‚’æ³¨æ„æ·±ãèª­ã¿ã€ãã®æƒ…å ±ã ã‘ã«åŸºã¥ã„ã¦ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã«ç­”ãˆãŒãªã„å ´åˆã¯ã€ã€Œåˆ†ã‹ã‚Šã¾ã›ã‚“ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸã®çŸ¥è­˜ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚

### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±:
{context}

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:
{question}

### å›ç­”:
"""
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])
    
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )

# --- 4. UIæç”»ã®é–¢æ•° ---

def draw_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®UIè¦ç´ ã‚’æç”»ã™ã‚‹é–¢æ•°"""
    with st.sidebar:
        st.header("ğŸ§  PocketAI Mentor")
        
        with st.expander("âš™ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—", expanded=True):
            # AIãƒ¢ãƒ‡ãƒ«é¸æŠ
            model_files = glob.glob(os.path.join(MODELS_DIR, "*.gguf"))
            if not model_files:
                st.error(f"`{MODELS_DIR}`ã«GGUFãƒ¢ãƒ‡ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            model_filenames = [os.path.basename(f) for f in model_files]
            
            # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾— ---
            try:
                model_index = model_filenames.index(st.session_state.get("selected_model", model_filenames[0]))
            except ValueError:
                model_index = 0
            selected_model_name = st.selectbox("1. AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", model_filenames, index=model_index)
            
            # PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
            uploaded_files = st.file_uploader(
                "2. æ–°ã—ã„PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type="pdf",
                accept_multiple_files=True
            )
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹å‡¦ç†
            if uploaded_files:
                for uploaded_file in uploaded_files:
                    filepath = os.path.join(UPLOADED_DOCS_DIR, uploaded_file.name)
                    if not os.path.exists(filepath):
                        with open(filepath, "wb") as f:
                            f.write(uploaded_file.getvalue())
                        st.success(f"ã€Œ{uploaded_file.name}ã€ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    else:
                        st.info(f"ã€Œ{uploaded_file.name}ã€ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
            
            st.divider()

            # ä¿å­˜ã•ã‚ŒãŸPDFã‚’é¸æŠã™ã‚‹æ©Ÿèƒ½
            stored_pdf_files = glob.glob(os.path.join(UPLOADED_DOCS_DIR, "*.pdf"))
            stored_pdf_filenames = sorted([os.path.basename(f) for f in stored_pdf_files])

            if not stored_pdf_filenames:
                 st.info("AIã«å‚ç…§ã•ã›ã‚‹PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            
            selected_pdf_names = st.multiselect(
                "3. å‚ç…§ã™ã‚‹PDFã‚’é¸æŠ",
                stored_pdf_filenames,
                default=st.session_state.get("selected_pdfs", [])
            )

            # èª­è¾¼å®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("èª­ã¿è¾¼ã‚€", type="primary", use_container_width=True):
                if not selected_pdf_names:
                    st.warning("å‚ç…§ã™ã‚‹PDFã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
                else:
                    load_resources(selected_model_name, selected_pdf_names)
        
        # --- ä¼šè©±ã®ç®¡ç† ---
        with st.expander("ğŸ“ ä¼šè©±ã®ç®¡ç†"):
            if st.button("æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹", use_container_width=True):
                st.session_state.messages = []
                st.session_state.qa_chain = None
                st.session_state.selected_model = ""
                st.session_state.selected_pdfs = []
                st.rerun()

            # ä¼šè©±ä¿å­˜ç”¨ã®UI
            save_name = st.text_input("ä¼šè©±ã®ä¿å­˜åï¼ˆæ‹¡å¼µå­ä¸è¦ï¼‰")
            if st.button("ç¾åœ¨ã®ä¼šè©±ã‚’ä¿å­˜", use_container_width=True):
                save_conversation(save_name)

            load_conversation()

def save_conversation(filename_prefix: str):
    """ç¾åœ¨ã®ä¼šè©±ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¨å…±ã«JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹é–¢æ•°"""
    if not st.session_state.get("qa_chain"):
        st.warning("ä¿å­˜ã™ã‚‹ä¼šè©±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚PDFã‚’èª­ã¿è¾¼ã‚“ã§ä¼šè©±ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        return

    if not st.session_state.messages:
        st.warning("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä½œæˆ
    conversation_data = {
        "model": st.session_state.selected_model,
        "pdfs": st.session_state.selected_pdfs,
        "messages": st.session_state.messages
    }

    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®š
    if filename_prefix:
        filename = f"{filename_prefix}.json"
    else:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"conversation_{ts}.json"
    
    filepath = os.path.join(CONVERSATIONS_DIR, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(conversation_data, f, ensure_ascii=False, indent=2)
    st.success(f"ä¼šè©±ã‚’ `{filename}` ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")


def load_conversation():
    """ä¿å­˜ã•ã‚ŒãŸä¼šè©±ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®UIã‚’æç”»ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¾©å…ƒã‚‚è¡Œã†é–¢æ•°"""
    conv_files = sorted(glob.glob(os.path.join(CONVERSATIONS_DIR, "*.json")), reverse=True)
    conv_filenames = [os.path.basename(f) for f in conv_files]
    
    if conv_filenames:
        st.divider()
        selected_conv = st.selectbox("ä¿å­˜ã—ãŸä¼šè©±ã‚’èª­ã¿è¾¼ã‚€", conv_filenames)
        if st.button("ã“ã®ä¼šè©±ã‚’èª­ã¿è¾¼ã‚€", use_container_width=True):
            filepath = os.path.join(CONVERSATIONS_DIR, selected_conv)
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            model_to_load = data.get("model")
            pdfs_to_load = data.get("pdfs", [])
            messages_to_load = data.get("messages", [])

            # å¾©å…ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨PDFãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            model_path = os.path.join(MODELS_DIR, model_to_load)
            pdf_paths_exist = all(os.path.exists(os.path.join(UPLOADED_DOCS_DIR, p)) for p in pdfs_to_load)

            if not os.path.exists(model_path):
                st.error(f"ãƒ¢ãƒ‡ãƒ« '{model_to_load}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return
            if not pdf_paths_exist:
                st.error("ä¿å­˜æ™‚ã®PDFã®ä¸€éƒ¨ã¾ãŸã¯ã™ã¹ã¦ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return

            # ãƒªã‚½ãƒ¼ã‚¹ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¾©å…ƒ
            load_resources(model_to_load, pdfs_to_load)
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¾©å…ƒ
            st.session_state.messages = messages_to_load
            st.rerun()

def load_resources(model_name, pdf_names):
    """
    é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨PDFã‚’èª­ã¿è¾¼ã¿ã€RAGãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
    å‡¦ç†å†…å®¹: LLMã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€RAGãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    with st.spinner("ãƒ¢ãƒ‡ãƒ«ã¨PDFã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
        model_path = os.path.join(MODELS_DIR, model_name)
        
        # ä¿å­˜ã•ã‚ŒãŸPDFã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        pdf_paths = [os.path.join(UPLOADED_DOCS_DIR, name) for name in pdf_names]
        
        # RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰
        # å‡¦ç†å†…å®¹: LlamaCppãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
        llm = LlamaCpp(
            model_path=model_path,
            # â˜…â˜… GPUè¨­å®š â˜…â˜…
            # ã“ã®æ•°å€¤ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—å‡¦ç†ã‚’GPUã«ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ï¼ˆå§”è­²ï¼‰ã—ã¾ã™ã€‚
            # -1 ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹å…¨ã¦ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒGPUã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
            # GPUã®VRAMå®¹é‡ãŒè¶³ã‚Šãªã„å ´åˆã¯ã€ã“ã®æ•°å€¤ã‚’èª¿æ•´ï¼ˆæ¸›ã‚‰ã™ï¼‰å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            # GPUã§å®Ÿè¡Œã™ã‚‹ã«ã¯ã€å¯¾å¿œã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…é ˆã§ã™ã€‚
            n_gpu_layers=-1,
            n_batch=512,
            n_ctx=4096,
            f16_kv=True,
            verbose=False,
        )
        embeddings = load_embeddings(EMBEDDING_MODEL)
        st.session_state.qa_chain = create_rag_chain(llm, embeddings, pdf_paths)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°
        st.session_state.selected_model = model_name
        st.session_state.selected_pdfs = pdf_names
        st.session_state.messages = []
        
    st.success("èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

def draw_welcome_message():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸç”»é¢ã‚’æç”»ã™ã‚‹é–¢æ•°"""
    st.header("ã‚ˆã†ã“ãï¼ PocketAI Mentorã¸")
    st.markdown("""
    ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ã‚ãªãŸãŒæŒ‡å®šã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã«ã¤ã„ã¦ã€AIã¨å¯¾è©±å½¢å¼ã§è³ªå•ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

    **åˆ©ç”¨æ–¹æ³•:**
    1.  å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚ã‚‹ **`âš™ï¸ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—`** ã‚’é–‹ãã¾ã™ã€‚
    2.  ä½¿ç”¨ã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¾ã™ã€‚
    3.  **ã€Œæ–°ã—ã„PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€** ã‚¨ãƒªã‚¢ã«PDFã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ã€AIã«å‚ç…§ã•ã›ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿ç®¡ã—ã¾ã™ã€‚
    4.  ä¿ç®¡ã•ã‚ŒãŸPDFã®ä¸­ã‹ã‚‰ã€**å‚ç…§ã—ãŸã„PDFã‚’é¸æŠ**ã—ã¾ã™ã€‚(è¤‡æ•°å¯)
    5.  **`èª­ã¿è¾¼ã‚€`** ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã€AIã®æº–å‚™ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¡ã¾ã™ã€‚
    6.  æº–å‚™ãŒå®Œäº†ã™ã‚‹ã¨ãƒãƒ£ãƒƒãƒˆç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã§ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚

    å…¨ã¦ã®å‡¦ç†ã¯ã‚ãªãŸã®PCå†…ã§å®Œçµã™ã‚‹ãŸã‚ã€æ©Ÿå¯†æƒ…å ±ã‚’å«ã‚€PDFã‚‚å®‰å…¨ã«æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ã€‚
    """)

# --- 5. ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§åˆ©ç”¨ã™ã‚‹å¤‰æ•°ã‚’st.session_stateã«åˆæœŸåŒ–ã—ã¾ã™ã€‚
if "messages" not in st.session_state:
    st.session_state.messages = []
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None
if "selected_model" not in st.session_state:
    st.session_state.selected_model = ""
if "selected_pdfs" not in st.session_state:
    st.session_state.selected_pdfs = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®æç”» ---
draw_sidebar()

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ã®æç”» ---
# RAGãƒã‚§ãƒ¼ãƒ³ãŒæº–å‚™ã§ãã¦ã„ã‚‹ã‹ã§ã€è¡¨ç¤ºã™ã‚‹ç”»é¢ã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚
if st.session_state.qa_chain:
    # --- ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º ---
    # é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«ã¨PDFã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¡¨ç¤ºã—ã¾ã™ã€‚
    st.markdown(
        f"**ğŸ§  ãƒ¢ãƒ‡ãƒ«:** `{st.session_state.selected_model}` "
        f"| **ğŸ“š å‚ç…§PDF:** `{'`, `'.join(st.session_state.selected_pdfs)}`"
    )
    st.divider()

    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•å…¥åŠ› ---
    if prompt := st.chat_input("PDFã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # --- AIã®å›ç­”ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º ---
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            handler = StreamlitCallbackHandler(message_placeholder)
            
            with st.spinner("ğŸ¤– å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                result = st.session_state.qa_chain.invoke(
                    prompt, 
                    config={"callbacks": [handler]}
                )
            
            response = result.get('result', "çµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚").strip()
            st.session_state.messages.append({"role": "assistant", "content": response})

            # --- å‚ç…§ã‚½ãƒ¼ã‚¹ã®è¡¨ç¤º ---
            # å›ç­”å¾Œã«ã€å‚ç…§ã—ãŸPDFã®ç®‡æ‰€ã‚’åˆ†ã‹ã‚Šã‚„ã™ãè¡¨ç¤ºã—ã¾ã™ã€‚
            with st.expander("å‚ç…§ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤º"):
                for doc in result.get('source_documents', []):
                    with st.container(border=True):
                        page_num = doc.metadata.get('page', 'N/A')
                        source_file = doc.metadata.get('source', 'N/A')
                        st.markdown(
                            f"**ãƒ•ã‚¡ã‚¤ãƒ«:** `{os.path.basename(source_file)}` | **ãƒšãƒ¼ã‚¸:** `{page_num + 1}`"
                        )
                        # å¼•ç”¨ç®‡æ‰€ã‚’æŠœç²‹ã—ã¦è¡¨ç¤º
                        st.caption(doc.page_content[:200].replace('\n', ' ') + "...")

else:
    # --- åˆæœŸç”»é¢ã®è¡¨ç¤º ---
    draw_welcome_message()

